{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MANE 4333\n",
    "\n",
    "## Week Twelve\n",
    "\n",
    "## MLP and SVM Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    outcome  time  radius  texture  perimeter    area  smoothness  \\\n",
      "0         N    31   18.02    27.60     117.50  1013.0     0.09489   \n",
      "1         N    61   17.99    10.38     122.80  1001.0     0.11840   \n",
      "2         N   116   21.37    17.44     137.50  1373.0     0.08836   \n",
      "3         N   123   11.42    20.38      77.58   386.1     0.14250   \n",
      "4         R    27   20.29    14.34     135.10  1297.0     0.10030   \n",
      "..      ...   ...     ...      ...        ...     ...         ...   \n",
      "189       N     3   14.72    25.26      99.28   657.5     0.11740   \n",
      "190       N    10   22.52    21.92     146.90  1597.0     0.07592   \n",
      "191       N     8   15.44    31.18     101.00   740.4     0.09399   \n",
      "192       N    12   17.17    29.19     110.00   915.3     0.08952   \n",
      "193       N     6   16.70    28.13     110.30   885.4     0.08896   \n",
      "\n",
      "     compactness  concavity  concavePoints  symmetry  fractal  tumorSize  \\\n",
      "0        0.10360    0.10860        0.07055    0.1865  0.06333        5.0   \n",
      "1        0.27760    0.30010        0.14710    0.2419  0.07871        3.0   \n",
      "2        0.11890    0.12550        0.08180    0.2333  0.06010        2.5   \n",
      "3        0.28390    0.24140        0.10520    0.2597  0.09744        2.0   \n",
      "4        0.13280    0.19800        0.10430    0.1809  0.05883        3.5   \n",
      "..           ...        ...            ...       ...      ...        ...   \n",
      "189      0.21120    0.17290        0.09465    0.2079  0.07496        1.7   \n",
      "190      0.09162    0.06862        0.06367    0.1728  0.05262        6.0   \n",
      "191      0.10620    0.13750        0.06500    0.1735  0.06105        1.5   \n",
      "192      0.06655    0.06583        0.05068    0.1793  0.05392        3.7   \n",
      "193      0.11310    0.10120        0.04989    0.1890  0.06035        3.5   \n",
      "\n",
      "     LymphStatus  recurrence  \n",
      "0              5           0  \n",
      "1              2           0  \n",
      "2              0           0  \n",
      "3              0           0  \n",
      "4              0           1  \n",
      "..           ...         ...  \n",
      "189           21           0  \n",
      "190            2           0  \n",
      "191            0           0  \n",
      "192            0           0  \n",
      "193            0           0  \n",
      "\n",
      "[194 rows x 15 columns]\n",
      "[[3.100e+01 1.802e+01 2.760e+01 ... 6.333e-02 5.000e+00 5.000e+00]\n",
      " [6.100e+01 1.799e+01 1.038e+01 ... 7.871e-02 3.000e+00 2.000e+00]\n",
      " [1.160e+02 2.137e+01 1.744e+01 ... 6.010e-02 2.500e+00 0.000e+00]\n",
      " ...\n",
      " [8.000e+00 1.544e+01 3.118e+01 ... 6.105e-02 1.500e+00 0.000e+00]\n",
      " [1.200e+01 1.717e+01 2.919e+01 ... 5.392e-02 3.700e+00 0.000e+00]\n",
      " [6.000e+00 1.670e+01 2.813e+01 ... 6.035e-02 3.500e+00 0.000e+00]]\n",
      "Confusion matrix for training set\n",
      "[[116   0]\n",
      " [ 39   0]]\n",
      "The accuracy for the training set is 0.748387\n",
      "Confusion matrix for test set\n",
      "[[32  0]\n",
      " [ 7  0]]\n",
      "The accuracy for the test set is 0.820513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dougl\\anaconda3\\envs\\env_4333\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - MLPClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# read excel file into dataframe\n",
    "df1 = pd.read_excel(open('wpbc.data.xlsx','rb'))\n",
    "df1=df1.dropna(axis=0,how='any')       # remove rows with missing values\n",
    "df1.drop('id', axis=1, inplace=True)   # drop column with patient ids\n",
    "print(df1)\n",
    "# create endogenous and exogenous variables\n",
    "X = np.array(df1.iloc[:, 1:14])\n",
    "print(X)\n",
    "y = np.array(df1['recurrence'])\n",
    "# split and transform data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=1114)\n",
    "X_train.shape\n",
    "# Transform training data\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_transformed=scaler.transform(X_train)\n",
    "X_test_transformed=scaler.transform(X_test)\n",
    "#fit model\n",
    "mlp1=MLPClassifier(hidden_layer_sizes=(13,5,5))\n",
    "mlp1.fit(X_train_transformed,y_train)\n",
    "y_train_pred = mlp1.predict(X_train_transformed)\n",
    "y_test_pred = mlp1.predict(X_test_transformed)\n",
    "# produce results\n",
    "print(\"Confusion matrix for training set\")\n",
    "print(confusion_matrix(y_train,y_train_pred))\n",
    "print(\"The accuracy for the training set is %f\"%mlp1.score(X_train_transformed,y_train))\n",
    "print(\"Confusion matrix for test set\")\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "print(\"The accuracy for the test set is %f\"%mlp1.score(X_test_transformed,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best parameters found:  {'mlp__activation': 'tanh', 'mlp__alpha': np.float64(0.045612125811931734), 'mlp__hidden_layer_sizes': (50, 50), 'mlp__learning_rate': 'adaptive', 'mlp__solver': 'adam'}\n",
      "Best cross-validation score:  0.7612903225806452\n",
      "Confusion matrix for training set\n",
      "[[116   0]\n",
      " [ 39   0]]\n",
      "The accuracy for the training set is 0.748387\n",
      "Confusion matrix for set set\n",
      "[[32  0]\n",
      " [ 7  0]]\n",
      "The accuracy for the test set is 0.820513\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - MLPClassifier with RandomizedSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# read excel file into dataframe\n",
    "df1 = pd.read_excel(open('wpbc.data.xlsx','rb'))\n",
    "df1=df1.dropna(axis=0,how='any')       # remove rows with missing values\n",
    "df1.drop('id', axis=1, inplace=True)   # drop column with patient ids\n",
    "#print(df1)\n",
    "# create endogenous and exogenous variables\n",
    "X = np.array(df1.iloc[:, 1:14])\n",
    "#print(X)\n",
    "y = np.array(df1['recurrence'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1114)\n",
    "\n",
    "# Define the pipeline with MinMaxScaler and MLPClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('mlp', MLPClassifier(max_iter=100))\n",
    "])\n",
    "\n",
    "# Define parameter space for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'mlp__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],\n",
    "    'mlp__activation': ['tanh', 'relu'],\n",
    "    'mlp__solver': ['sgd', 'adam'],\n",
    "    'mlp__alpha': uniform(0.0001, 0.1),\n",
    "    'mlp__learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    random_state=1114,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation score: \", random_search.best_score_)\n",
    "\n",
    "# Test the best model on the test set\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Generate predictions and confusion matrices for both training and test sets\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute and display confusion matrix for training set\n",
    "train_cm = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Confusion matrix for training set\")\n",
    "print(train_cm)\n",
    "print(\"The accuracy for the training set is %f\"%best_model.score(X_train,y_train))\n",
    "\n",
    "# Compute and display confusion matrix for test set\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion matrix for set set\")\n",
    "print(test_cm)\n",
    "print(\"The accuracy for the test set is %f\"%best_model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "Best parameters found:  {'mlp__activation': 'relu', 'mlp__alpha': 0.1, 'mlp__hidden_layer_sizes': (100, 100), 'mlp__learning_rate': 'adaptive', 'mlp__solver': 'adam'}\n",
      "Best cross-validation score:  0.7870967741935484\n",
      "Confusion matrix for training set\n",
      "[[113   3]\n",
      " [ 24  15]]\n",
      "The accuracy for the training set is 0.825806\n",
      "Confusion matrix for set set\n",
      "[[27  5]\n",
      " [ 4  3]]\n",
      "The accuracy for the test set is 0.769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dougl\\anaconda3\\envs\\env_4333\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Example 3 - MLPClassifier with GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# read excel file into dataframe\n",
    "df1 = pd.read_excel(open('wpbc.data.xlsx','rb'))\n",
    "df1=df1.dropna(axis=0,how='any')       # remove rows with missing values\n",
    "df1.drop('id', axis=1, inplace=True)   # drop column with patient ids\n",
    "#print(df1)\n",
    "# create endogenous and exogenous variables\n",
    "X = np.array(df1.iloc[:, 1:14])\n",
    "#print(X)\n",
    "y = np.array(df1['recurrence'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1114)\n",
    "\n",
    "# Define the pipeline with MinMaxScaler and MLPClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('mlp', MLPClassifier(max_iter=100))\n",
    "])\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'mlp__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 100)],\n",
    "    'mlp__activation': ['tanh', 'relu'],\n",
    "    'mlp__solver': ['sgd', 'adam'],\n",
    "    'mlp__alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'mlp__learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Test the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Generate predictions and confusion matrices for both training and test sets\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute and display confusion matrix for training set\n",
    "train_cm = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Confusion matrix for training set\")\n",
    "print(train_cm)\n",
    "print(\"The accuracy for the training set is %f\"%best_model.score(X_train,y_train))\n",
    "\n",
    "# Compute and display confusion matrix for test set\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion matrix for set set\")\n",
    "print(test_cm)\n",
    "print(\"The accuracy for the test set is %f\"%best_model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for training set\n",
      "[[  0 116]\n",
      " [  0  39]]\n",
      "The accuracy for the training set is 0.251613\n",
      "Confusion matrix for test set\n",
      "[[ 0 32]\n",
      " [ 0  7]]\n",
      "The accuracy for the test set is 0.179487\n"
     ]
    }
   ],
   "source": [
    "# Example 4 - Linear SVM \n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# Define the LinearSVC model\n",
    "linear_svc = LinearSVC(C=1.0, max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "linear_svc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#\n",
    "y_train_pred = linear_svc.predict(X_train_transformed)\n",
    "y_test_pred = linear_svc.predict(X_test_transformed)\n",
    "# produce results\n",
    "print(\"Confusion matrix for training set\")\n",
    "print(confusion_matrix(y_train,y_train_pred))\n",
    "print(\"The accuracy for the training set is %f\"%linear_svc.score(X_train_transformed,y_train))\n",
    "print(\"Confusion matrix for test set\")\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "print(\"The accuracy for the test set is %f\"%linear_svc.score(X_test_transformed,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for training set\n",
      "[[116   0]\n",
      " [ 39   0]]\n",
      "The accuracy for the training set is 0.748387\n",
      "Confusion matrix for test set\n",
      "[[32  0]\n",
      " [ 7  0]]\n",
      "The accuracy for the test set is 0.820513\n"
     ]
    }
   ],
   "source": [
    "# Example 5 - SVM with RBF Kernel\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the SVM model with an RBF kernel\n",
    "svm_rbf = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "#\n",
    "y_train_pred = svm_rbf.predict(X_train_transformed)\n",
    "y_test_pred = svm_rbf.predict(X_test_transformed)\n",
    "# produce results\n",
    "print(\"Confusion matrix for training set\")\n",
    "print(confusion_matrix(y_train,y_train_pred))\n",
    "print(\"The accuracy for the training set is %f\"%svm_rbf.score(X_train_transformed,y_train))\n",
    "print(\"Confusion matrix for test set\")\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "print(\"The accuracy for the test set is %f\"%svm_rbf.score(X_test_transformed,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for training set\n",
      "[[116   0]\n",
      " [ 39   0]]\n",
      "The accuracy for the training set is 0.748387\n",
      "Confusion matrix for test set\n",
      "[[32  0]\n",
      " [ 7  0]]\n",
      "The accuracy for the test set is 0.820513\n"
     ]
    }
   ],
   "source": [
    "# Example 6 - SVM Classifier - third order polynomial\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the SVM model with a third-order polynomial kernel\n",
    "svm_poly = SVC(kernel='poly', degree=3, C=1.0, gamma='scale', random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm_poly.fit(X_train, y_train)\n",
    "\n",
    "#\n",
    "y_train_pred = svm_poly.predict(X_train_transformed)\n",
    "y_test_pred = svm_poly.predict(X_test_transformed)\n",
    "# produce results\n",
    "print(\"Confusion matrix for training set\")\n",
    "print(confusion_matrix(y_train,y_train_pred))\n",
    "print(\"The accuracy for the training set is %f\"%svm_poly.score(X_train_transformed,y_train))\n",
    "print(\"Confusion matrix for test set\")\n",
    "print(confusion_matrix(y_test,y_test_pred))\n",
    "print(\"The accuracy for the test set is %f\"%svm_poly.score(X_test_transformed,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 7 - SVM Classifier - RandomizedSearchCV polyomial\n",
    "# not working - takes too long to execute\n",
    "\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "#from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "#from scipy.stats import uniform\n",
    "\n",
    "# Define the SVM model\n",
    "#svm_poly = SVC(kernel='poly', random_state=42)\n",
    "\n",
    "# Define the parameter distributions for RandomizedSearchCV\n",
    "#param_dist = {\n",
    "#    'C': uniform(0.1, 10.0),            # Regularization parameter\n",
    "#    'degree': [2, 3],                   # Second- and third-order polynomials\n",
    "#    'gamma': ['scale', 'auto'],         # Kernel coefficient\n",
    "#    'coef0': uniform(0, 1),             # Independent term in polynomial kernel\n",
    "#}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "#random_search = RandomizedSearchCV(\n",
    "#    estimator=svm_poly,\n",
    "#    param_distributions=param_dist,\n",
    "#    n_iter=4,                          # Number of random combinations to try\n",
    "#    cv=2,                               # 5-fold cross-validation\n",
    "#    verbose=2,\n",
    "#    random_state=1114,\n",
    "#    n_jobs=-1                           # Use all available CPU cores\n",
    "#)\n",
    "\n",
    "# Fit the model with randomized search\n",
    "#random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "#print(\"Best parameters found: \", random_search.best_params_)\n",
    "#print(\"Best cross-validation score: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for set set\n",
      "[[32  0]\n",
      " [ 7  0]]\n",
      "The accuracy for the test set is 0.769231\n"
     ]
    }
   ],
   "source": [
    "# Example 8 - SVM Classifier - GridSearchCV polyomial\n",
    "# not working - takes too long to execute\n",
    "\n",
    "#from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "#from sklearn.svm import SVC\n",
    "\n",
    "# Set up the parameter grid for GridSearchCV\n",
    "#param_grid = {\n",
    "#    'C': [0.1, 1, 10, 100],\n",
    "#    'degree': [2, 3],  # Polynomial degrees to try\n",
    "#    'gamma': ['scale', 'auto'],\n",
    "#    'kernel': ['poly']\n",
    "#}\n",
    "\n",
    "# Initialize the SVM model\n",
    "#svm = SVC()\n",
    "\n",
    "# Set up GridSearchCV with cross-validation\n",
    "#grid_search = GridSearchCV(svm, param_grid, refit=True, cv=5)\n",
    "\n",
    "# Fit the model to the training data\n",
    "#grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "#print(\"Best parameters found: \", grid_search.best_params_)\n",
    "#print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Test the best model on the test set\n",
    "#best_model = grid_search.best_estimator_\n",
    "\n",
    "# Generate predictions and confusion matrices for both training and test sets\n",
    "#y_train_pred = best_model.predict(X_train)\n",
    "#y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute and display confusion matrix for training set\n",
    "#train_cm = confusion_matrix(y_train, y_train_pred)\n",
    "#print(\"Confusion matrix for training set\")\n",
    "#print(train_cm)\n",
    "#print(\"The accuracy for the training set is %f\"%best_model.score(X_train,y_train))\n",
    "\n",
    "# Compute and display confusion matrix for test set\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion matrix for set set\")\n",
    "print(test_cm)\n",
    "print(\"The accuracy for the test set is %f\"%best_model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "Best cross-validation score:  0.7612903225806452\n",
      "Confusion matrix for training set\n",
      "[[115   1]\n",
      " [ 21  18]]\n",
      "The accuracy for the training set is 0.858065\n",
      "Confusion matrix for set set\n",
      "[[30  2]\n",
      " [ 7  0]]\n",
      "The accuracy for the test set is 0.769231\n"
     ]
    }
   ],
   "source": [
    "# Example 9 - SVM Classifier - RBF Kernel - Grid Search\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set up the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm = SVC()\n",
    "\n",
    "# Set up GridSearchCV with cross-validation\n",
    "grid_search = GridSearchCV(svm, param_grid, refit=True, cv=5)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and the best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Test the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Generate predictions and confusion matrices for both training and test sets\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Compute and display confusion matrix for training set\n",
    "train_cm = confusion_matrix(y_train, y_train_pred)\n",
    "print(\"Confusion matrix for training set\")\n",
    "print(train_cm)\n",
    "print(\"The accuracy for the training set is %f\"%best_model.score(X_train,y_train))\n",
    "\n",
    "# Compute and display confusion matrix for test set\n",
    "test_cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion matrix for set set\")\n",
    "print(test_cm)\n",
    "print(\"The accuracy for the test set is %f\"%best_model.score(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
